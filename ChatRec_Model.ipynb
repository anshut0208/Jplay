{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Chat Reply Recommendation Model\n", "Preprocessing, training, evaluation, and reply generation using GPT-2.\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Imports\n", "import pandas as pd\n", "import torch\n", "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n", "from utils import clean_text\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Load datasets\n", "userA_df = pd.read_csv('./dataset/userA_chats.csv')\n", "userB_df = pd.read_csv('./dataset/userB_chats.csv')\n", "userA_df['clean_text'] = userA_df['message'].apply(clean_text)\n", "userB_df['clean_text'] = userB_df['message'].apply(clean_text)\n", "conversations = list(zip(userB_df['clean_text'], userA_df['clean_text']))\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Tokenizer and Model\n", "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n", "tokenizer.pad_token = tokenizer.eos_token\n", "model = GPT2LMHeadModel.from_pretrained('gpt2')\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Encode data and prepare for training\n", "from torch.utils.data import Dataset\n", "\n", "class ChatDataset(Dataset):\n", "    def __init__(self, conversations, tokenizer, max_length=128):\n", "        self.inputs = []\n", "        self.labels = []\n", "        for b_msg, a_msg in conversations:\n", "            enc = tokenizer.encode_plus(b_msg + tokenizer.eos_token + a_msg,\n", "                                        truncation=True,\n", "                                        padding='max_length',\n", "                                        max_length=max_length,\n", "                                        return_tensors='pt')\n", "            self.inputs.append(enc['input_ids'].squeeze())\n", "            self.labels.append(enc['input_ids'].squeeze())\n", "\n", "    def __len__(self):\n", "        return len(self.inputs)\n", "\n", "    def __getitem__(self, idx):\n", "        return {'input_ids': self.inputs[idx], 'labels': self.labels[idx]}\n", "\n", "dataset = ChatDataset(conversations, tokenizer)\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Training arguments\n", "training_args = TrainingArguments(\n", "    output_dir='./model',\n", "    num_train_epochs=1,\n", "    per_device_train_batch_size=2,\n", "    save_steps=100,\n", "    save_total_limit=2,\n", "    logging_steps=50\n", ")\n", "\n", "# Trainer\n", "trainer = Trainer(\n", "    model=model,\n", "    args=training_args,\n", "    train_dataset=dataset,\n", "    tokenizer=tokenizer\n", ")\n", "\n", "trainer.train()\n", "model.save_pretrained('./model')\n", "tokenizer.save_pretrained('./model')"]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}